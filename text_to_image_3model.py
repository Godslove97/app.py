# -*- coding: utf-8 -*-
"""Text_to_image=3model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17znJffOKbbHXe3FA4iSw8O4wvnfEal1G
"""

# from google.colab import files
# uploaded = files.upload()

# !pip install   transformers pillow requests

# set TF_ENABLE_ONEDNN_OPTS=0
from transformers import pipeline
from PIL import Image
import warnings


"""###  image to text Ai

"""

def image_to_text(history_image):
  # Load the image pipeline
  history = pipeline("image-to-text", model="Salesforce/blip-image-captioning-large")

  # Generate text from the image
  text = history(history_image)
  generated_text = text[0]['generated_text'].upper()

  # using ANSI escape codes
  blue_text = f"\033[34m{generated_text}\033[0m"
  return blue_text

art_history = image_to_text("/content/WhatsApp Image 2024-08-21 at 08.32.19_48279a5c.jpg")
print(art_history)

# !touch .env

# !pip install python-dotenv

import os
# install pip install python-dotenv ===on  the terminal
#
# from http.client import responses

from dotenv import load_dotenv
load_dotenv()

# test = os.getenv("SECRET_KEY")
# print(test)

from openai import OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

responses = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {
            "role": "user",
            "content": [
                {
                "type": "text",
                "text": "what is Genealogical history and  family tree"
                }
            ]
        },
    ],

    temperature=0.1,
    max_tokens=1000,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
    response_format={
      "type": "text"
    }
)
# print(responses)

responses = responses.choices[0].message.content.upper()
print(responses)

"""### TEXT TO video

"""

import requests
import json
import os


HUGGINGFACEHUB_API_TOKEN =  os.getenv("HUGGINGFACEHUB_API_TOKEN")
os.environ["HUGGINGFACEHUB_API_TOKEN"] = HUGGINGFACEHUB_API_TOKEN


def text_to_video(responses):
  API_URL="https://api-inference.huggingface.co/models/rain1011/pyramid-flow-miniflux"
  headers={"Authorization":f"Bearer {HUGGINGFACEHUB_API_TOKEN}"}
  payloads={
      "inputs":responses
  }




  response=requests.post(API_URL,headers=headers,json=payloads)
  return response.content

